# ------------------------------------------------------------------------------------
#  Performance Summary (Reusable Workflow) (GoFortress)
#
#  Purpose: Generate a comprehensive performance summary report for the entire
#  workflow run, including timing metrics, cache statistics, and test results.
#
#  Maintainer: @mrz1836
#
# ------------------------------------------------------------------------------------

name: GoFortress (Performance Summary)

on:
  workflow_call:
    inputs:
      benchmarks-result:
        description: "Benchmarks job result"
        required: false
        type: string
        default: "skipped"
      start-epoch:
        description: "Workflow start epoch time"
        required: true
        type: string
      start-time:
        description: "Workflow start time"
        required: true
        type: string
      setup-result:
        description: "Setup job result"
        required: true
        type: string
      test-magex-result:
        description: "Test MAGE-X job result"
        required: true
        type: string
      security-result:
        description: "Security job result"
        required: true
        type: string
      code-quality-result:
        description: "Code quality job result"
        required: true
        type: string
      pre-commit-result:
        description: "Pre-commit checks job result"
        required: true
        type: string
      test-suite-result:
        description: "Test suite job result"
        required: true
        type: string
      release-result:
        description: "Result of the release job"
        required: false
        type: string
        default: "skipped"
      status-check-result:
        description: "Result of the status-check job"
        required: false
        type: string
        default: "skipped"
      test-matrix:
        description: "Test matrix JSON"
        required: true
        type: string
      env-json:
        description: "JSON string of environment variables"
        required: true
        type: string
      primary-runner:
        description: "Primary runner OS"
        required: true
        type: string

# Security: Restrictive default permissions with job-level overrides for least privilege access
permissions:
  contents: read

jobs:
  # ----------------------------------------------------------------------------------
  # Performance Summary Report
  # ----------------------------------------------------------------------------------
  performance-summary:
    name: üìä Performance Summary Report
    runs-on: ${{ inputs.primary-runner }}
    steps:
      # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
      # Parse environment variables
      # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
      - name: üîß Parse environment variables
        env:
          ENV_JSON: ${{ inputs.env-json }}
        run: |
          echo "üìã Setting environment variables..."
          echo "$ENV_JSON" | jq -r 'to_entries | .[] | "\(.key)=\(.value)"' | while IFS='=' read -r key value; do
            echo "$key=$value" >> $GITHUB_ENV
          done

      # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
      # Download all statistics artifacts
      # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
      - name: üì• Download performance artifacts
        if: always()
        uses: actions/download-artifact@634f93cb2916e3fdff6788551b99b062d0335ce0 # v5.0.0
        with:
          pattern: "*-stats-*"
          path: ./performance-artifacts/

      # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
      # Flatten performance artifacts for processing
      # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
      - name: üóÇÔ∏è Flatten performance artifacts
        if: always()
        run: |
          echo "üóÇÔ∏è Flattening downloaded artifacts..."

          # Find all JSON files in subdirectories and move them to current directory
          if [ -d "./performance-artifacts/" ]; then
            find ./performance-artifacts/ -name "*.json" -type f | while read -r file; do
              filename=$(basename "$file")
              echo "Moving $file to ./$filename"
              cp "$file" "./$filename"
            done

            # List all flattened files for debugging
            echo "üìã Available stats files:"
            ls -la *-stats-*.json 2>/dev/null || echo "No stats files found"
          else
            echo "‚ö†Ô∏è No performance-artifacts directory found"
          fi

      # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
      # Generate performance report
      # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
      - name: üìä Generate Performance Report
        id: generate-performance-report
        run: |
          # Calculate total duration
          START_EPOCH=${{ inputs.start-epoch }}
          END_EPOCH=$(date +%s)
          TOTAL_DURATION=$((END_EPOCH - START_EPOCH))
          TOTAL_MINUTES=$((TOTAL_DURATION / 60))
          TOTAL_SECONDS=$((TOTAL_DURATION % 60))

          # Store as outputs for later use
          echo "total_minutes=$TOTAL_MINUTES" >> $GITHUB_OUTPUT
          echo "total_seconds=$TOTAL_SECONDS" >> $GITHUB_OUTPUT
          echo "total_duration=$TOTAL_DURATION" >> $GITHUB_OUTPUT

          # Start performance summary
          {
            echo "## üìä Workflow Performance Metrics"
            echo ""
            echo "### ‚è±Ô∏è Overall Timing"
            echo "| Metric | Value |"
            echo "|--------|-------|"
            echo "| **Total Duration** | ${TOTAL_MINUTES}m ${TOTAL_SECONDS}s |"
            echo "| **Start Time** | ${{ inputs.start-time }} |"
            echo "| **End Time** | $(date -u +"%Y-%m-%dT%H:%M:%SZ") |"
            echo "| **Workflow** | ${{ github.workflow }} |"
            echo "| **Run Number** | ${{ github.run_number }} |"
            echo "| **Trigger** | ${{ github.event_name }} |"
            echo "| **Source** | ${{ github.event.pull_request.head.repo.full_name == github.repository && 'Internal' || 'Fork' }} |"
            echo ""

            # Process cache statistics if available
            # Use a more robust file existence check
            if compgen -G "cache-stats-*.json" >/dev/null 2>&1; then
              echo ""
              echo "### üíæ Cache Performance"
              echo "| OS | Go Version | Module Cache | Build Cache | Module Size | Build Size |"
              echo "|----|------------|--------------|-------------|-------------|------------|"

              TOTAL_CACHE_HITS=0
              TOTAL_CACHE_ATTEMPTS=0

              for stats_file in cache-stats-*.json; do
                if [ -f "$stats_file" ]; then
                  OS=$(jq -r '.os' "$stats_file")
                  GO_VER=$(jq -r '.go_version' "$stats_file")
                  GOMOD_HIT=$(jq -r '.gomod_cache_hit' "$stats_file")
                  GOBUILD_HIT=$(jq -r '.gobuild_cache_hit' "$stats_file")
                  GOMOD_SIZE=$(jq -r '.cache_size_gomod' "$stats_file")
                  GOBUILD_SIZE=$(jq -r '.cache_size_gobuild' "$stats_file")

                  GOMOD_ICON=$([[ "$GOMOD_HIT" == "true" ]] && echo "‚úÖ Hit" || echo "‚ùå Miss")
                  GOBUILD_ICON=$([[ "$GOBUILD_HIT" == "true" ]] && echo "‚úÖ Hit" || echo "‚ùå Miss")

                  echo "| $OS | $GO_VER | $GOMOD_ICON | $GOBUILD_ICON | $GOMOD_SIZE | $GOBUILD_SIZE |"

                  [[ "$GOMOD_HIT" == "true" ]] && TOTAL_CACHE_HITS=$((TOTAL_CACHE_HITS + 1))
                  [[ "$GOBUILD_HIT" == "true" ]] && TOTAL_CACHE_HITS=$((TOTAL_CACHE_HITS + 1))
                  TOTAL_CACHE_ATTEMPTS=$((TOTAL_CACHE_ATTEMPTS + 2))
                fi
              done
            fi

            # Process benchmark statistics if available
            # Use a more robust file existence check
            if compgen -G "benchmark-stats-*.json" >/dev/null 2>&1; then
              echo ""
              echo ""
              echo "### üèÉ Benchmark Performance"

              # Get benchmark mode from the first stats file
              BENCH_MODE="normal"
              for stats_file in benchmark-stats-*.json; do
                if [ -f "$stats_file" ]; then
                  BENCH_MODE=$(jq -r '.benchmark_mode // "normal"' "$stats_file")
                  break
                fi
              done

              echo "**Mode**: \`$BENCH_MODE\` $(case "$BENCH_MODE" in quick) echo "(Quick 50ms runs)" ;; full) echo "(Comprehensive 10s runs)" ;; *) echo "(Normal 100ms runs)" ;; esac)"
              echo ""

              echo "| Benchmark Suite | Duration | Benchmarks | Status |"
              echo "|-----------------|----------|------------|--------|"

              for stats_file in benchmark-stats-*.json; do
                if [ -f "$stats_file" ]; then
                  NAME=$(jq -r '.name' "$stats_file")
                  DURATION=$(jq -r '.duration_seconds' "$stats_file")
                  BENCHMARK_COUNT=$(jq -r '.benchmark_count' "$stats_file")
                  STATUS=$(jq -r '.status' "$stats_file")
                  BENCHMARK_SUMMARY=$(jq -r '.benchmark_summary' "$stats_file")

                  DURATION_MIN=$((DURATION / 60))
                  DURATION_SEC=$((DURATION % 60))
                  STATUS_ICON=$([[ "$STATUS" == "success" ]] && echo "‚úÖ" || echo "‚ùå")

                  echo "| $NAME | ${DURATION_MIN}m ${DURATION_SEC}s | $BENCHMARK_COUNT | $STATUS_ICON |"
                fi
              done

              # Display detailed benchmark results
              echo ""
              echo "<details>"
              echo "<summary>Detailed Benchmark Results</summary>"
              echo ""

              for stats_file in benchmark-stats-*.json; do
                if [ -f "$stats_file" ]; then
                  NAME=$(jq -r '.name' "$stats_file")
                  BENCHMARK_SUMMARY=$(jq -r '.benchmark_summary' "$stats_file")
                  if [ -n "$BENCHMARK_SUMMARY" ] && [ "$BENCHMARK_SUMMARY" != "null" ]; then
                    echo "#### $NAME"
                    echo "$BENCHMARK_SUMMARY"
                    echo ""
                  fi
                fi
              done

              echo "</details>"
            fi

            # Process test statistics if available
            # Use a more robust file existence check
            if compgen -G "test-stats-*.json" >/dev/null 2>&1; then
              echo ""
              echo ""
              echo "### üß™ Test Execution Performance"
              echo "| Test Suite | Mode | Duration | Tests | Failed | Packages | Status | Race | Coverage |"
              echo "|------------|------|----------|-------|--------|----------|--------|------|----------|"

              # Initialize totals for summary
              TOTAL_TESTS=0
              TOTAL_FAILURES=0
              TOTAL_AFFECTED_PACKAGES=0
              SUITE_COUNT=0

              for stats_file in test-stats-*.json; do
                if [ -f "$stats_file" ]; then
                  NAME=$(jq -r '.name' "$stats_file")
                  DURATION=$(jq -r '.duration_seconds' "$stats_file")
                  TEST_COUNT=$(jq -r '.test_count' "$stats_file")
                  EXAMPLE_COUNT=$(jq -r '.example_count' "$stats_file")
                  STATUS=$(jq -r '.status' "$stats_file")
                  RACE_ENABLED=$(jq -r '.race_enabled' "$stats_file")
                  COVERAGE_ENABLED=$(jq -r '.coverage_enabled' "$stats_file")

                  # New enhanced fields
                  TEST_MODE=$(jq -r '.test_mode // "unknown"' "$stats_file")
                  SUITE_FAILURES=$(jq -r '.total_failures // 0' "$stats_file")
                  AFFECTED_PACKAGES=$(jq -r '.affected_packages // 0' "$stats_file")

                  DURATION_MIN=$((DURATION / 60))
                  DURATION_SEC=$((DURATION % 60))

                  COVERAGE_ICON=$([[ "$COVERAGE_ENABLED" == "true" ]] && echo "‚úÖ" || echo "‚ùå")
                  RACE_ICON=$([[ "$RACE_ENABLED" == "true" ]] && echo "‚úÖ" || echo "‚ùå")
                  STATUS_ICON=$([[ "$STATUS" == "success" ]] && echo "‚úÖ" || echo "‚ùå")

                  # Show package count or dash
                  PACKAGE_DISPLAY=$([[ "$AFFECTED_PACKAGES" -gt 0 ]] && echo "$AFFECTED_PACKAGES" || echo "-")

                  echo "| $NAME | $TEST_MODE | ${DURATION_MIN}m ${DURATION_SEC}s | $TEST_COUNT | $SUITE_FAILURES | $PACKAGE_DISPLAY | $STATUS_ICON | $RACE_ICON | $COVERAGE_ICON |"

                  # Accumulate totals
                  TOTAL_TESTS=$((TOTAL_TESTS + TEST_COUNT))
                  TOTAL_FAILURES=$((TOTAL_FAILURES + SUITE_FAILURES))
                  TOTAL_AFFECTED_PACKAGES=$((TOTAL_AFFECTED_PACKAGES + AFFECTED_PACKAGES))
                  SUITE_COUNT=$((SUITE_COUNT + 1))
                fi
              done

              # Add test failure analysis if any failures exist
              if [[ $TOTAL_FAILURES -gt 0 ]]; then
                echo ""
                echo ""
                echo "### ‚ùå Test Failure Analysis"
                echo "**Total Failures**: $TOTAL_FAILURES across $SUITE_COUNT test suite(s)"
                echo ""

                # Show failure breakdown by suite
                echo "#### üìä Failures by Test Suite:"
                for stats_file in test-stats-*.json; do
                  if [ -f "$stats_file" ]; then
                    SUITE_NAME=$(jq -r '.name' "$stats_file")
                    SUITE_FAILURES=$(jq -r '.total_failures // 0' "$stats_file")
                    SUITE_PACKAGES=$(jq -r '.affected_packages // 0' "$stats_file")

                    if [[ $SUITE_FAILURES -gt 0 ]]; then
                      echo "- **$SUITE_NAME**: $SUITE_FAILURES failures across $SUITE_PACKAGES packages"
                    fi
                  fi
                done

                echo ""
                echo "<details>"
                echo "<summary>üîç Top Failed Tests (click to expand)</summary>"
                echo ""
                echo "| Test Name | Package | Duration | Suite |"
                echo "|-----------|---------|----------|-------|"

                # Extract detailed failure information from all suites
                FAILURE_COUNT=0
                for stats_file in test-stats-*.json; do
                  if [ -f "$stats_file" ] && [[ $FAILURE_COUNT -lt 20 ]]; then
                    SUITE_NAME=$(jq -r '.name' "$stats_file")
                    FAILURE_DETAILS=$(jq -r '.failure_details // null' "$stats_file")

                    if [[ "$FAILURE_DETAILS" != "null" ]] && [[ "$FAILURE_DETAILS" != "[]" ]]; then
                      echo "$FAILURE_DETAILS" | jq -r --arg suite "$SUITE_NAME" \
                        '.[] | "| \(.test) | \(.package | split("/") | .[-1] // .[-2] // .) | \(.duration // "unknown")s | \($suite) |"' 2>/dev/null | \
                        head -10 || true
                      FAILURE_COUNT=$((FAILURE_COUNT + 10))
                    fi
                  fi
                done

                echo ""
                echo "</details>"
              fi

              # Add test output configuration section
              echo ""
              echo ""
              echo "### üéõÔ∏è Test Output Configuration"
              echo "| Configuration | Value | Description |"
              echo "|---------------|-------|-------------|"
              echo "| **Mode** | ${TEST_OUTPUT_MODE:-SMART} | Test output strategy |"
              echo "| **Smart Threshold** | ${TEST_OUTPUT_SMART_THRESHOLD:-500} tests | Switch to FAILURES_ONLY above this |"
              echo "| **Failure Limit** | ${TEST_FAILURE_MAX_COUNT:-100} | Max failures to capture |"
              echo "| **Detail Count** | ${TEST_FAILURE_DETAIL_COUNT:-50} | Failures shown with details |"
              echo "| **Annotations** | ${TEST_FAILURE_ANNOTATION_COUNT:-10} | GitHub annotations limit |"
              echo "| **Artifacts** | $([ "${TEST_OUTPUT_SAVE_ARTIFACTS:-true}" == "true" ] && echo "‚úÖ Enabled" || echo "‚ùå Disabled") | ${TEST_OUTPUT_ARTIFACT_RETENTION_DAYS:-7} day retention |"

              # Show output strategy summary
              if [[ $SUITE_COUNT -gt 0 ]]; then
                FULL_MODE_COUNT=0
                FAILURES_ONLY_COUNT=0

                for stats_file in test-stats-*.json; do
                  if [ -f "$stats_file" ]; then
                    MODE=$(jq -r '.test_mode // "unknown"' "$stats_file")
                    if [[ "$MODE" == "FULL" ]]; then
                      FULL_MODE_COUNT=$((FULL_MODE_COUNT + 1))
                    elif [[ "$MODE" == "FAILURES_ONLY" ]]; then
                      FAILURES_ONLY_COUNT=$((FAILURES_ONLY_COUNT + 1))
                    fi
                  fi
                done

                echo ""
                echo "**Output Strategy Summary:**"
                echo "- $FULL_MODE_COUNT suite(s) used FULL mode (complete output)"
                echo "- $FAILURES_ONLY_COUNT suite(s) used FAILURES_ONLY mode (efficient extraction)"

                if [[ $FAILURES_ONLY_COUNT -gt 0 ]]; then
                  echo "- Estimated output size reduction: ~80-90% for large test suites"
                fi
              fi

              # Process Lines of Code Summary
              DISPLAYED_LOC_SUMMARY=false

              for stats_file in test-stats-*.json; do
                if [ -f "$stats_file" ] && [ "$DISPLAYED_LOC_SUMMARY" = false ]; then
                  # Extract individual LOC values from the JSON
                  TEST_FILES_COUNT=$(jq -r '.loc_test_files' "$stats_file")
                  GO_FILES_COUNT=$(jq -r '.loc_go_files' "$stats_file")
                  TOTAL_LOC=$(jq -r '.loc_total' "$stats_file")
                  LOC_DATE=$(jq -r '.loc_date' "$stats_file")

                  echo ""
                  echo ""
                  echo "### üìä Lines of Code Summary"
                  echo "| Type | Total Lines | Date |"
                  echo "|------|-------------|------|"
                  echo "| Test Files | $TEST_FILES_COUNT | $LOC_DATE |"
                  echo "| Go Files | $GO_FILES_COUNT | $LOC_DATE |"
                  echo ""
                  echo "**Total lines of code: $TOTAL_LOC**"
                  DISPLAYED_LOC_SUMMARY=true
                fi
              done
            fi

            # Process fuzz test statistics - always show status
            echo ""
            echo ""
            echo "### üéØ Fuzz Test Performance"

            # Check if fuzz testing is enabled in environment
            if [[ "${{ env.ENABLE_FUZZ_TESTING }}" == "true" ]]; then
              # Fuzz testing is enabled, check for stats files
              if compgen -G "fuzz-stats-*.json" >/dev/null 2>&1; then
                echo "| Fuzz Suite | Duration | Fuzz Tests | Status | Enabled |"
                echo "|------------|----------|------------|--------|---------|"

                for stats_file in fuzz-stats-*.json; do
                  if [ -f "$stats_file" ]; then
                    NAME=$(jq -r '.name' "$stats_file")
                    DURATION=$(jq -r '.duration_seconds' "$stats_file")
                    FUZZ_TEST_COUNT=$(jq -r '.fuzz_test_count' "$stats_file")
                    STATUS=$(jq -r '.status' "$stats_file")

                    DURATION_MIN=$((DURATION / 60))
                    DURATION_SEC=$((DURATION % 60))

                    STATUS_ICON=$([[ "$STATUS" == "success" ]] && echo "‚úÖ" || echo "‚ùå")

                    echo "| $NAME | ${DURATION_MIN}m ${DURATION_SEC}s | $FUZZ_TEST_COUNT | $STATUS_ICON | üéØ |"
                  fi
                done
              else
                # Fuzz testing enabled but no stats found
                echo "| Status | Details |"
                echo "|--------|---------|"
                echo "| **Fuzz Testing** | ‚úÖ Enabled |"
                echo "| **Execution** | ‚ö†Ô∏è No fuzz stats found - check job logs |"
                echo "| **Platform** | Linux with primary Go version |"
              fi
            else
              # Fuzz testing is disabled
              echo "| Status | Details |"
              echo "|--------|---------|"
              echo "| **Fuzz Testing** | ‚ùå Disabled |"
              echo "| **Configuration** | Set ENABLE_FUZZ_TESTING=true to enable |"
              echo "| **Target Platform** | Would run on Linux with primary Go version |"
            fi

            # Process coverage statistics if available
            if compgen -G "coverage-stats-*.json" >/dev/null 2>&1; then
              echo ""
              echo ""
              echo "### üìä Coverage System Performance"

              for stats_file in coverage-stats-*.json; do
                if [ -f "$stats_file" ]; then
                  echo "| Metric | Value |"
                  echo "|--------|-------|"

                  COVERAGE_PERCENT=$(jq -r '.coverage_percent // "N/A"' "$stats_file")
                  PROCESSING_TIME=$(jq -r '.processing_time_seconds // "N/A"' "$stats_file")
                  FILES_PROCESSED=$(jq -r '.files_processed // "N/A"' "$stats_file")
                  BADGE_GENERATED=$(jq -r '.badge_generated // "false"' "$stats_file")
                  PAGES_DEPLOYED=$(jq -r '.pages_deployed // "false"' "$stats_file")

                  echo "| **Coverage Percentage** | $COVERAGE_PERCENT% |"
                  echo "| **Processing Time** | ${PROCESSING_TIME}s |"
                  echo "| **Files Processed** | $FILES_PROCESSED |"
                  echo "| **Badge Generated** | $([ "$BADGE_GENERATED" == "true" ] && echo "‚úÖ Yes" || echo "‚ùå No") |"
                  echo "| **Pages Deployed** | $([ "$PAGES_DEPLOYED" == "true" ] && echo "‚úÖ Yes" || echo "‚ùå No") |"

                  break # Only show first coverage stats file
                fi
              done
            elif [[ "${{ env.ENABLE_CODE_COVERAGE }}" == "true" ]]; then
              echo ""
              echo ""
              echo "### üìä Coverage System Status"
              echo "| Status | Details |"
              echo "|--------|---------|"
              echo "| **System** | Internal GoFortress Coverage |"
              echo "| **Threshold** | ${{ env.GO_COVERAGE_THRESHOLD }}% minimum |"
              echo "| **Badge Style** | ${{ env.GO_COVERAGE_BADGE_STYLE }} |"
              echo "| **PR Comments** | $([ "${{ env.GO_COVERAGE_POST_COMMENTS }}" == "true" ] && echo "‚úÖ Enabled" || echo "‚ùå Disabled") |"
              echo "| **Theme** | ${{ env.GO_COVERAGE_REPORT_THEME }} |"
            fi

            echo ""
            echo "### üîß Job Results Summary"
            echo "| Job | Status | Result |"
            echo "|-----|--------|--------|"
            echo "| üéØ Setup Configuration | ${{ inputs.setup-result }} | $([ "${{ inputs.setup-result }}" = "success" ] && echo "‚úÖ" || echo "‚ùå") |"
            echo "| ü™Ñ Test MAGE-X | ${{ inputs.test-magex-result }} | $([ "${{ inputs.test-magex-result }}" = "success" ] && echo "‚úÖ" || echo "‚ùå") |"
            echo "| ü™ù Pre-commit Checks | ${{ inputs.pre-commit-result }} | $([ "${{ inputs.pre-commit-result }}" = "success" ] && echo "‚úÖ" || echo "‚ùå") |"
            echo "| üîí Security Scans | ${{ inputs.security-result }} | $([ "${{ inputs.security-result }}" = "success" ] && echo "‚úÖ" || echo "‚ùå") |"
            echo "| üìä Code Quality | ${{ inputs.code-quality-result }} | $([ "${{ inputs.code-quality-result }}" = "success" ] && echo "‚úÖ" || echo "‚ùå") |"
            echo "| üß™ Test Suite | ${{ inputs.test-suite-result }} | $([ "${{ inputs.test-suite-result }}" = "success" ] && echo "‚úÖ" || echo "‚ùå") |"
            # Only show benchmarks row if it was attempted
            if [[ "${{ inputs.benchmarks-result }}" != "skipped" ]]; then
              echo "| üèÉ Benchmarks | ${{ inputs.benchmarks-result }} | $([ "${{ inputs.benchmarks-result }}" = "success" ] && echo "‚úÖ" || echo "‚ùå") |"
            fi
            # Always show status-check result
            echo "| üéØ All Tests Passed | ${{ inputs.status-check-result }} | $([ "${{ inputs.status-check-result }}" = "success" ] && echo "‚úÖ" || echo "‚ùå") |"
            # Only show release row if it was attempted
            if [[ "${{ inputs.release-result }}" != "skipped" ]]; then
              echo "| üöÄ Release | ${{ inputs.release-result }} | $([ "${{ inputs.release-result }}" = "success" ] && echo "‚úÖ" || echo "‚ùå") |"
            fi

            echo ""

            # Add release-specific information if this was a tag push
            if [[ "${{ github.ref }}" == refs/tags/v* ]]; then
              echo ""
              echo "## üì¶ Release Information"
              if [[ "${{ inputs.release-result }}" == "success" ]]; then
                echo "‚úÖ Release ${{ github.ref_name }} created successfully!"
                echo "[View Release](https://github.com/${{ github.repository }}/releases/tag/${{ github.ref_name }})"
              elif [[ "${{ inputs.release-result }}" == "skipped" ]]; then
                echo "‚è≠Ô∏è Release was skipped (likely due to test failures)"
              elif [[ "${{ inputs.release-result }}" == "failure" ]]; then
                echo "‚ùå Release creation failed - check logs for details"
              fi
              echo ""
            fi

            echo ""

            echo ""
            echo "### üöÄ Performance Insights"

            # Overall timing insights
            if [[ $TOTAL_DURATION -gt 600 ]]; then
              echo "- ‚ö†Ô∏è  **Warning**: Workflow took longer than 10 minutes (${TOTAL_MINUTES}m ${TOTAL_SECONDS}s)"
            elif [[ $TOTAL_DURATION -gt 300 && $TOTAL_DURATION -le 600 ]]; then
              echo "- ‚ÑπÔ∏è  Workflow completed in ${TOTAL_MINUTES}m ${TOTAL_SECONDS}s."
            elif [[ $TOTAL_DURATION -gt 180 && $TOTAL_DURATION -le 300 ]]; then
              echo "- üéâ  **Great Performance**: Workflow completed in under 5 minutes (${TOTAL_MINUTES}m ${TOTAL_SECONDS}s)!"
            elif [[ $TOTAL_DURATION -le 180 ]]; then
              echo "- üöÄ  **Excellent Performance**: Workflow completed in under 3 minutes!"
            fi

            # Test-specific insights based on collected data
            if compgen -G "test-stats-*.json" >/dev/null 2>&1; then
              # Calculate test-specific metrics
              FULL_MODE_SUITES=0
              FAILURES_ONLY_SUITES=0
              ESTIMATED_SAVINGS_MB=0

              for stats_file in test-stats-*.json; do
                if [ -f "$stats_file" ]; then
                  MODE=$(jq -r '.test_mode // "unknown"' "$stats_file")
                  TEST_COUNT=$(jq -r '.test_count // 0' "$stats_file")
                  OUTPUT_SIZE=$(jq -r '.output_size_bytes // 0' "$stats_file")

                  if [[ "$MODE" == "FULL" ]]; then
                    FULL_MODE_SUITES=$((FULL_MODE_SUITES + 1))
                  elif [[ "$MODE" == "FAILURES_ONLY" ]]; then
                    FAILURES_ONLY_SUITES=$((FAILURES_ONLY_SUITES + 1))
                    # Estimate savings (assume FULL mode would be 5-10x larger)
                    ESTIMATED_FULL_SIZE=$((OUTPUT_SIZE * 7))
                    SAVINGS=$((ESTIMATED_FULL_SIZE - OUTPUT_SIZE))
                    ESTIMATED_SAVINGS_MB=$((ESTIMATED_SAVINGS_MB + SAVINGS / 1048576))
                  fi
                fi
              done

              echo "- **Test Strategy**: $FULL_MODE_SUITES suite(s) used FULL output, $FAILURES_ONLY_SUITES used efficient FAILURES_ONLY"

              if [[ $TOTAL_FAILURES -gt 0 ]]; then
                FAILURE_RATE=$(( (TOTAL_FAILURES * 10000) / TOTAL_TESTS ))  # Calculate percentage * 100 for precision
                FAILURE_RATE_DISPLAY=$(( FAILURE_RATE / 100 )).$(( FAILURE_RATE % 100 ))
                echo "- **Failure Rate**: $FAILURE_RATE_DISPLAY% ($TOTAL_FAILURES/$TOTAL_TESTS tests)"

                # Find most affected package
                MOST_AFFECTED_PACKAGE=""
                MAX_FAILURES=0
                for stats_file in test-stats-*.json; do
                  if [ -f "$stats_file" ]; then
                    FAILURE_DETAILS=$(jq -r '.failure_details // null' "$stats_file")
                    if [[ "$FAILURE_DETAILS" != "null" ]] && [[ "$FAILURE_DETAILS" != "[]" ]]; then
                      # Extract package with most failures
                      PACKAGE_FAILURES=$(echo "$FAILURE_DETAILS" | jq -r 'group_by(.package) | map({package: .[0].package, count: length}) | max_by(.count)' 2>/dev/null)
                      if [[ "$PACKAGE_FAILURES" != "null" ]]; then
                        PKG_NAME=$(echo "$PACKAGE_FAILURES" | jq -r '.package | split("/") | .[-1] // .[-2] // .')
                        PKG_COUNT=$(echo "$PACKAGE_FAILURES" | jq -r '.count')
                        if [[ $PKG_COUNT -gt $MAX_FAILURES ]]; then
                          MAX_FAILURES=$PKG_COUNT
                          MOST_AFFECTED_PACKAGE="$PKG_NAME"
                        fi
                      fi
                    fi
                  fi
                done

                if [[ -n "$MOST_AFFECTED_PACKAGE" ]] && [[ $MAX_FAILURES -gt 0 ]]; then
                  echo "- **Most Affected Package**: $MOST_AFFECTED_PACKAGE ($MAX_FAILURES failures)"
                fi
              else
                echo "- **Test Success**: All $TOTAL_TESTS tests passed! üéâ"
              fi

              if [[ $ESTIMATED_SAVINGS_MB -gt 0 ]]; then
                echo "- **Output Efficiency**: Saved approximately ${ESTIMATED_SAVINGS_MB}MB by using FAILURES_ONLY mode"
              fi
            fi

            # Standard insights
            echo "- **Parallel Jobs**: Multiple jobs ran in parallel to optimize execution time"
            echo "- **Matrix Strategy**: Tests ran across $(echo '${{ inputs.test-matrix }}' | jq '.include | length') configurations"
            if [ "${{ env.ENABLE_VERBOSE_TEST_OUTPUT }}" != "true" ]; then
              echo "- **Verbose Output**: Disabled to speed up test execution"
            else
              echo "- **Verbose Output**: Enabled for detailed test logs"
            fi

            # Add failure analysis if any job failed
            FAILED_JOBS=""
            [ "${{ inputs.setup-result }}" != "success" ] && [ "${{ inputs.setup-result }}" != "skipped" ] && FAILED_JOBS="${FAILED_JOBS}Setup Configuration, "
            [ "${{ inputs.test-magex-result }}" != "success" ] && [ "${{ inputs.test-magex-result }}" != "skipped" ] && FAILED_JOBS="${FAILED_JOBS}Test MAGE-X, "
            [ "${{ inputs.pre-commit-result }}" != "success" ] && [ "${{ inputs.pre-commit-result }}" != "skipped" ] && FAILED_JOBS="${FAILED_JOBS}Pre-commit Checks, "
            [ "${{ inputs.security-result }}" != "success" ] && [ "${{ inputs.security-result }}" != "skipped" ] && FAILED_JOBS="${FAILED_JOBS}Security Scans, "
            [ "${{ inputs.code-quality-result }}" != "success" ] && [ "${{ inputs.code-quality-result }}" != "skipped" ] && FAILED_JOBS="${FAILED_JOBS}Code Quality, "
            [ "${{ inputs.test-suite-result }}" != "success" ] && [ "${{ inputs.test-suite-result }}" != "skipped" ] && FAILED_JOBS="${FAILED_JOBS}Test Suite, "
            [ "${{ inputs.benchmarks-result }}" != "success" ] && [ "${{ inputs.benchmarks-result }}" != "skipped" ] && FAILED_JOBS="${FAILED_JOBS}Benchmarks, "
            [ "${{ inputs.status-check-result }}" != "success" ] && [ "${{ inputs.status-check-result }}" != "skipped" ] && FAILED_JOBS="${FAILED_JOBS}Status Check, "
            [ "${{ inputs.release-result }}" != "success" ] && [ "${{ inputs.release-result }}" != "skipped" ] && FAILED_JOBS="${FAILED_JOBS}Release, "

            if [ -n "$FAILED_JOBS" ]; then
              FAILED_JOBS=${FAILED_JOBS%, }  # Remove trailing comma
              echo ""
              echo ""
              echo "### ‚ùå Failed Jobs"
              echo "The following jobs did not complete successfully:"
              echo "- ${FAILED_JOBS}"
            fi

          } >> $GITHUB_STEP_SUMMARY

          echo "‚úÖ Performance summary report generated successfully"
